{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spelling corrector challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we deal with  unigram language model. Our goal is to get a spelling corrector with a good accuracy and process speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "WORDS = Counter(words(open('big.txt').read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While fast typing, it is more likely to make a mistake in adding a character than replacing. The idea is to give a higher probability to longer words. The accuracy improved the most (about 1-5%) using an exponential scale, which confirm our hypothesis. People do make many more errors when typing longer words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language model : estimate the probability of a word\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word]*10**(len(word))/ N\n",
    "\n",
    "# Error model \n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word),key=P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115585"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N=sum(WORDS.values())\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Candidate model function\n",
    "def candidates(word):\n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known(google_checker(word))or known(insert_rst(word)) or known(duplicate_edit (word)) or  known([word]) or known(edits1(word)) or known(edits2(word)) or [word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict words to known\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Candidate model of the baseline\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improvement on Candidate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify typing errors in our candidate model and see if it improves our accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time, a misspelled word looks similar to the actual word. It is very unlikely that someone missing 4 characters in a word. It is also to long to consider the more than 3 edit errors cases. Therefore, we make allowance for at most 2 mistakes - 2 edit distance away. This helps us maximising our accuracy. In order to improve our model, we need to think about which are the most common mistakes : For example, it is a common mistake to repeat a same character, to insert a letter or to omit repetition of letters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the edits number away from word : I abandon this idea, it is not that common to do 3 edit errors in a word \n",
    "#def edits3(word):\n",
    "#    \"All edits that are three edits away from `word.\"\n",
    "#    return (e3 for e2 in edits2(word) for e3 in edits2(e2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It is more common to do duplicate error, by adding duplicate function we improved the speed of our corrector.\n",
    "def duplicate_edit (word):\n",
    "    \"Duplicates letters\"\n",
    "    splits = [(word[:i], word[i:])for i in range(len(word) + 1)]\n",
    "    inserts = [L + R[0] + R for L, R in splits if R]\n",
    "    return set(inserts)\n",
    "\n",
    "# we can try to only consider most common letters in English\n",
    "def insert_rst(word):\n",
    "    letters    = 'rst'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(inserts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following shows some attemps that I think will improve the model, but turn out to give little imporvement or even make the model less accurate, so I did not include them in the candidate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete or insert a letter\n",
    "def delete_edit(word):\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    return set(deletes)\n",
    "\n",
    "def insert_edit(word):\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(inserts)\n",
    "\n",
    "# swap letters  \n",
    "def trans2_edit(word):\n",
    "    letters     = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits      = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    transposes0 = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    transposes1 = [L + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    transposes2 = [L + R[1] + R[2:] for L, R in splits if len(R)>1]\n",
    "    return set(transposes0 + transposes1 + transposes2 )\n",
    "\n",
    "# vowel mistyping is a common mistake \n",
    "def vowels_edit(word):\n",
    "    vowels = ['a','e','i','o','u','y']\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    replaces   = [L + c + R[1:]          for L, R in splits if R for c in vowels]\n",
    "    return set(replaces )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following shows some other attemps that can be used in the model. But adding with other functions (especially with duplicate_edit), they do not present much improvement , so I did not include in the candidate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar(char):\n",
    "    \"Generates some similar characters if char satisfies any of conditions\"\n",
    "    if (char == 'c'):\n",
    "        return 's'\n",
    "    if (char == 's'):\n",
    "        return 'c'\n",
    "    if (char == 'b'):\n",
    "        return 'p'\n",
    "    if (char == 'p'):\n",
    "        return 'b'\n",
    "    if (char == 'n'):\n",
    "        return 'm'\n",
    "    if (char == 'm'):\n",
    "        return 'n'\n",
    "    if (char == 'd'):\n",
    "        return 't'\n",
    "    if (char == 't'):\n",
    "        return 'd'\n",
    "    else:\n",
    "        return ''\n",
    "    \n",
    "def similar_edit(word):\n",
    "    \"Getting set of where chars are replaced by similar ones (if any) (common mictake?)\"\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    replaces   = [L + c + R[1:]   for L, R in splits if R for c in similar(R[0])]\n",
    "    return set(replaces)\n",
    "\n",
    "def close(char):\n",
    "    \"Generates the most common consonants R S T for some close on the keyboard characters if char satisfies any of conditions\"\n",
    "    if (char == 'a'):\n",
    "        return 's'\n",
    "    if (char == 'w'):\n",
    "        return 's'\n",
    "    if (char == 'd'):\n",
    "        return 's'\n",
    "    if (char == 'z'):\n",
    "        return 's'\n",
    "    if (char == 'x'):\n",
    "        return 's'\n",
    "    if (char == 'e'):\n",
    "        return 'r'\n",
    "    if (char == 'f'):\n",
    "        return 'r'\n",
    "    if (char == 'g'):\n",
    "        return 't'\n",
    "    if (char == 'y'):\n",
    "        return 't'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def close_edit(word):\n",
    "    \"Getting set of where chars are replaced by closed ones (if any)\"\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    replaces   = [L + c + R[1:]     for L, R in splits if R for c in close(R[0])]\n",
    "    return set(replaces)\n",
    "\n",
    "def rare(char):\n",
    "    \"Generates some close on the keyboard characters for the rarest letters in english J Q X Z\"\n",
    "    if (char == 'j'):\n",
    "        return 'k'\n",
    "    if (char == 'j'):\n",
    "        return 'h'\n",
    "    if (char == 'j'):\n",
    "        return 'u'\n",
    "    if (char == 'j'):\n",
    "        return 'm'\n",
    "    if (char == 'j'):\n",
    "        return 'n'\n",
    "    if (char == 'j'):\n",
    "        return 'm'\n",
    "    if (char == 'q'):\n",
    "        return 'w'\n",
    "    if (char == 'q'):\n",
    "        return 'a'\n",
    "    if (char == 'x'):\n",
    "        return 'c'\n",
    "    if (char == 'x'):\n",
    "        return 'd'\n",
    "    if (char == 'z'):\n",
    "        return 'a'\n",
    "    else:\n",
    "        return ''\n",
    "    \n",
    "def rare_edit(word):\n",
    "    \"Getting set of where chars are replaced by closed ones (if any)\"\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    replaces   = [L + c + R[1:]     for L, R in splits if R for c in rare(R[0])]\n",
    "    \n",
    "    return set(replaces)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google checker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a program that I found on the internet that turned out to be very useful. It obtains the corrected word checked from Google and check if such word exists in big.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  requests, re\n",
    "from html.parser import HTMLParser\n",
    "import urllib3\n",
    "class GoogleSpellCheckCommand(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"Construtor\"\n",
    "        self.manager = urllib3.PoolManager()\n",
    "\n",
    "    def correct(self, text):\n",
    "        \"Correct input text by using Google Spell Corrector\"\n",
    "        \n",
    "        # grab html\n",
    "        html = self.get_page('http://www.google.com/search?hl=en&q=' + requests.utils.quote(text) + \"&meta=&gws_rd=ssl\")\n",
    "        html_parser = HTMLParser()\n",
    "\n",
    "        # save html for debugging\n",
    "        # open('page.html', 'w').write(html)\n",
    "\n",
    "        # pull pieces out\n",
    "        match = re.search(r'(?:Showing results for|Did you mean|Including results for)[^\\0]*?<a.*?>(.*?)</a>', html)\n",
    "        if match is None:\n",
    "            fix = text\n",
    "        else:\n",
    "            fix = match.group(1)\n",
    "            fix = re.sub(r'<.*?>', '', fix)\n",
    "            fix = html_parser.unescape(fix)\n",
    "        # return result\n",
    "        return fix\n",
    "\n",
    "    def get_page(self, url):\n",
    "        # the type of header affects the type of response google returns\n",
    "        # for example, using the commented out header below google does not \n",
    "        # include \"Including results for\" results and gives back a different set of results\n",
    "        # than using the updated user_agent yanked from chrome's headers\n",
    "        # user_agent = 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.7) Gecko/2009021910 Firefox/3.0.7'\n",
    "        user_agent = 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.116 Safari/537.36'\n",
    "        headers = {'User-Agent':user_agent,}\n",
    "\n",
    "        req =  self.manager.request('GET', url, headers)\n",
    "        \n",
    "        return str(req.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_checker(word):\n",
    "    google_corrector = GoogleSpellCheckCommand()\n",
    "    \n",
    "    return [google_corrector.correct(word)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also wanted to try pyEnchant. It is a python package for spell checking and correcting that help to get similar words suggestion. But I had trouble in getting the enchant library installed. But I think it will successfully improve the accuracy of the model, by checking if the most likely words are in big.txt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spelltest(tests, verbose=False):\n",
    "    \"Run correction(wrong) on all (right, wrong) pairs; report results.\"\n",
    "    import time\n",
    "    start = time.clock()\n",
    "    good, unknown = 0, 0\n",
    "    n = len(tests)\n",
    "    for right, wrong in tests:\n",
    "        w = correction(wrong)\n",
    "        good += (w == right)\n",
    "        if w != right:\n",
    "            unknown += (right not in WORDS)\n",
    "            if verbose:\n",
    "                print('correction({}) => {} ({}); expected {} ({})'\n",
    "                      .format(wrong, w, WORDS[w], right, WORDS[right]))\n",
    "    dt = time.clock() - start\n",
    "    print('{:.0%} of {} correct ({:.0%} unknown) at {:.0f} words per second '\n",
    "          .format(good / n, n, unknown / n, n / dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Testset(lines):\n",
    "    \"Parse 'right: wrong1 wrong2' lines into [('right', 'wrong1'), ('right', 'wrong2')] pairs.\"\n",
    "    return [(right, wrong)\n",
    "            for (right, wrongs) in (line.split(':') for line in lines)\n",
    "            for wrong in wrongs.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  after removing the cwd from sys.path.\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:27: DeprecationWarning: The unescape method is deprecated and will be removed in 3.5, use html.unescape() instead.\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86% of 270 correct (6% unknown) at 45 words per second \n",
      "79% of 400 correct (11% unknown) at 35 words per second \n",
      "56% of 531 correct (23% unknown) at 19 words per second \n",
      "67% of 2455 correct (24% unknown) at 22 words per second \n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    spelltest(Testset(open('spell-testset1.txt')))\n",
    "    spelltest(Testset(open('spell-testset2.txt')))\n",
    "    spelltest(Testset(open('aspell.txt')))\n",
    "    spelltest(Testset(open('wikipedia.txt')))\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I get around 10% better in accuracy, with a better precessing words speed : 5 to 12 words/second better. In order to do better, we can try to add some costs to edits in the error model to penalize rare mistakes, and continue to improve our correction model : for example by adding a limited set of words at edit distance 3. If we want to go further, we will want to consider surrounding words, which will help a lot in selecting the right word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
